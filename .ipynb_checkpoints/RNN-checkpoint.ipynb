{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def forward(self, x):\n",
    "        return np.tanh(x)\n",
    "    def backward(self, x, diff):\n",
    "        output = np.tanh(x)\n",
    "        return (1.0 - np.square(output)) * diff\n",
    "    \n",
    "class sigmoid:\n",
    "    def forward(self, x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "    def backward(self, x, diff):\n",
    "        output = self.forward(x)\n",
    "        return (1.0-output)*output*diff\n",
    "    \n",
    "class softmax:\n",
    "    def predict(self, x):\n",
    "        return np.exp(x)/np.sum(np.exp(x))\n",
    "    def loss(self, x, y):\n",
    "        probs = self.predict(x)\n",
    "        return -np.log(probs[y])\n",
    "    def diff(self, x, y):\n",
    "        probs = self.predict(x)\n",
    "        probs[y] -= 1.0\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiplyGate:\n",
    "    def forward(self, x, w):\n",
    "        return np.dot(x, w)\n",
    "    \n",
    "    def backward(self, x, w, dz):\n",
    "        dw = np.dot(x.T, dz)\n",
    "        dx = np.dot(dz, w.T)\n",
    "        return dw, dx\n",
    "    \n",
    "class AddGate:\n",
    "    def forward(self, x1, x2):\n",
    "        return x1 + x2\n",
    "    \n",
    "    def backward(self, x1, x2, dz):\n",
    "        dx1 = np.dot(dz.T, np.ones([dz.shape[0], x1.shape[1]]))\n",
    "        dx2 = np.dot(dz.T, np.ones([dz.shape[0], x2.shape[1]]))\n",
    "        return dx1, dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mulGate = MultiplyGate()\n",
    "addGate = AddGate()\n",
    "activation = Tanh()\n",
    "\n",
    "class RNNLayer:\n",
    "    def forward(self, x, prev_s, U, W, V):\n",
    "        self.mulu = mulGate.forward(x, U)\n",
    "        self.mulw = mulGate.forward(x, prev_s)\n",
    "        self.adduw = addGate.forward(self.mulu, self.mulw)\n",
    "        self.state = activation.forward(self.adduw)\n",
    "        self.mulo = mulGate.forward(self.state, V)\n",
    "    \n",
    "    def backward(self, x, prev_s, U, W, V, diff, dmulv):\n",
    "        self.forward(x, prev_s, U, W, V)\n",
    "        dV, dVx = mulGate.backward(x, V, dmulv)\n",
    "        dadd = activation.backward(self.adduw, dVx)\n",
    "        dmulu, dmulw = addGate.backward(self.mulu, dmulw, dadd)\n",
    "        dU, dUx = mulGate.backward(self.x, U, dmulu)\n",
    "        dW, dWx = mulGate.backward(prev_s, W, dmulw)\n",
    "        return dU, dW, dV\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_dim, hidden_nodes, output_dim, lr = 0.001, bptt_truncate = 4):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_dim = output_dim\n",
    "        self.U = np.random.random([input_dim, hidden_nodes])*0.01\n",
    "        self.W = np.random.random([hidden_nodes, hidden_nodes])*0.01\n",
    "        self.V = np.random.random([hidden_nodes, output_dim])*0.01\n",
    "        self.lr = lr\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "\n",
    "    def forward(self, x):  \n",
    "        # total number of time steps\n",
    "        # each steps input a word\n",
    "        self.time_steps = len(x)\n",
    "        layers = []\n",
    "        prev_s = np.zeros([self.hidden_nodes])\n",
    "        for t in range(time_steps):\n",
    "            layer = RNNLayer()\n",
    "            input_vec = np.zeros(self.word_dim)\n",
    "            input_vec[x[t]] = 1\n",
    "            layer.forward(input_vec, prev_s, self.U, self.W, self.V)\n",
    "            prev_s = layer.state\n",
    "            layers.append(layer)\n",
    "        return layers\n",
    "    \n",
    "    def backward(self, x, y):\n",
    "        dU = np.zeros_like(self.U)\n",
    "        dW = np.zeros_like(self.W)\n",
    "        dV = np.zeros_like(self.V)\n",
    "        layers = self.forward(x)\n",
    "        for t in range(self.time_steps):\n",
    "            dmulv = output.diff(layers[t],mulv, y[t])\n",
    "            input_vec = np.zeros(self.word_dim)\n",
    "            input_vec[x[t]] = 1\n",
    "            dU_t, dW_t, dV_t = layers[t].backward(input_vec, prev_s, self.U, self.W, self.V, dmulv)\n",
    "            for i in range(t-1,max(-1, t-self.bptt_truncate-1),-1):\n",
    "                input_vec = np.zeros(self.word_dim)\n",
    "                input_vec[x[i]] = 1\n",
    "                prev_s_i = np.zeros(self.hidden_nodes) if i == 0 else layers[i-1].state\n",
    "                dU_i, dW_i, dV_i = layers[i].backward(input_vec, prev_s_i, self.U, self.W, self.V, dmulv)\n",
    "                dU_t += dU_i\n",
    "                dW_t += dW_i\n",
    "                dV_t += dV_i\n",
    "            dU += dU_t\n",
    "            dW += dW_t\n",
    "            dV += dV_t\n",
    "        return dU, dW, dV\n",
    "    \n",
    "    def sgd_optimizer(self, x, y, lr):\n",
    "        dU, dW, dV = self.backward(x,y)\n",
    "        self.U -= lr*dU\n",
    "        self.W -= lr*dW\n",
    "        self.V -= lr*dV\n",
    "    \n",
    "    def caculate_loss(self, x, y):\n",
    "        loss = 0.0\n",
    "        for example in range(len(y)):\n",
    "            single_loss = 0.0\n",
    "            for j in range(x.shape[1])\n",
    "                layer = self.forward(x[example][j])\n",
    "                single_loss += output.loss(layer.mulv, y[example][j])\n",
    "            loss += (single_loss/x.shape[1])\n",
    "            \n",
    "    \n",
    "    def train(self, x, y, lr=0.005, nepoch=100, evaluate_loss_after=5):     \n",
    "        for epoch in nepoch:\n",
    "            if epoch % evaluate_loss_after == 0:\n",
    "                loss = self.caculate_loss(x,y)\n",
    "                print(\"Epoch=%d   Loss=%f\" % (epoch, loss))\n",
    "            for i in range(len(y)):\n",
    "                self.sgd_optimizer(x[i], y[i], lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(binary_dim, largest_number, int2binary):\n",
    "    a = np.random.randint(largest_number/2)\n",
    "    b = np.random.randint(largest_number/2)\n",
    "    c = a + b\n",
    "    return a,b,c,int2binary[a], int2binary[b], int2binary[c]\n",
    "\n",
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "largest_number = pow(2, binary_dim)\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]    \n",
    "\n",
    "rnn = RNN(2, 16, 1)\n",
    "for j in range(10000):\n",
    "    # a, b, c is the [1, binaray_dim] vector\n",
    "    inta, intb, intc, a, b, c = generate_data(binary_dim, largest_number, int2binary)\n",
    "    x = np.stack((a,b))\n",
    "    y = np.array(c)\n",
    "    # hidden layer : input + prev_hidden\n",
    "    reverse_x = np.fliplr(x)\n",
    "    reverse_y = y[::-1]\n",
    "    states, output = rnn.forward(reverse_x)\n",
    "    #loss = rnn.backward(reverse_x, reverse_y, states, output)\n",
    "    if j%1000 == 0:\n",
    "        print(inta,intb,c,\"error: \",loss)\n",
    "        print('predict: ',end=\"\")\n",
    "        for i in output[::-1]:\n",
    "            if i >= 0.5:\n",
    "                print(\"1\",end=\" \")\n",
    "            else:\n",
    "                print(\"0\",end=\" \")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
